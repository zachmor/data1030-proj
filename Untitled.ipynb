{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefd64d6-bdee-44f9-b6af-44459b107e3c",
   "metadata": {},
   "source": [
    "DATA1030 TERM PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f66bd78b-55c9-4828-b4a8-201963c4a584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 22.2.2 from /Users/zacharymor/anaconda3/envs/data1030/lib/python3.10/site-packages/pip (python 3.10)\n",
      "Collecting quiverquant==0.1.57\n",
      "  Using cached quiverquant-0.1.57-py3-none-any.whl (5.1 kB)\n",
      "Collecting alpha_vantage==2.3.1\n",
      "  Using cached alpha_vantage-2.3.1-py3-none-any.whl (31 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.5.1-cp310-cp310-macosx_10_9_x86_64.whl (12.0 MB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.3-cp310-cp310-macosx_10_9_x86_64.whl (358 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.1-cp310-cp310-macosx_10_9_x86_64.whl (35 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.1-cp310-cp310-macosx_10_9_x86_64.whl (61 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl (28 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.5-py2.py3-none-any.whl (500 kB)\n",
      "Collecting numpy>=1.21.0\n",
      "  Using cached numpy-1.23.4-cp310-cp310-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "Collecting python-dateutil>=2.8.1\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, urllib3, six, numpy, multidict, idna, frozenlist, charset-normalizer, certifi, attrs, async-timeout, yarl, requests, python-dateutil, aiosignal, pandas, aiohttp, quiverquant, alpha_vantage\n",
      "  changing mode of /Users/zacharymor/anaconda3/envs/data1030/bin/f2py to 755\n",
      "  changing mode of /Users/zacharymor/anaconda3/envs/data1030/bin/f2py3 to 755\n",
      "  changing mode of /Users/zacharymor/anaconda3/envs/data1030/bin/f2py3.10 to 755\n",
      "  changing mode of /Users/zacharymor/anaconda3/envs/data1030/bin/normalizer to 755\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.55.2 requires numpy<1.23,>=1.18, but you have numpy 1.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-3.8.3 aiosignal-1.2.0 alpha_vantage-2.3.1 async-timeout-4.0.2 attrs-22.1.0 certifi-2022.9.24 charset-normalizer-2.1.1 frozenlist-1.3.1 idna-3.4 multidict-6.0.2 numpy-1.23.4 pandas-1.5.1 python-dateutil-2.8.2 pytz-2022.5 quiverquant-0.1.57 requests-2.28.1 six-1.16.0 urllib3-1.26.12 yarl-1.8.1\n"
     ]
    }
   ],
   "source": [
    "#Install dependencies... \n",
    "! pip install -Iv quiverquant==0.1.57 alpha_vantage==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6abd04bd-bae2-411a-878f-7477bbb5aac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting...\n",
      "https://api.quiverquant.com/beta/live/congresstrading\n",
      "downloaded congress_trading\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/cryptocomments\n",
      "couldnt download cryptoComments\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/cryptocommentsfull\n",
      "couldnt download cryptoCommentsHistorical\n",
      "downloaded flights\n",
      "downloaded gov_contracts\n",
      "NOT CALLABLE  headers\n",
      "downloaded house_trading\n",
      "Drawing from:  https://api.quiverquant.com/beta/live/insiders\n",
      "downloaded insiders\n",
      "downloaded lobbying\n",
      "downloaded offexchange\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/allpatents\n",
      "downloaded patents\n",
      "downloaded political_beta\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/sec13f\n",
      "downloaded sec13F\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/sec13fchanges\n",
      "downloaded sec13FChanges\n",
      "downloaded senate_trading\n",
      "downloaded spacs\n",
      "NOT CALLABLE  token\n",
      "downloaded twitter\n",
      "https://api.quiverquant.com/beta/live/wallstreetbets?count_all=true\n",
      "downloaded wallstreetbets\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/wsbcomments\n",
      "couldnt download wallstreetbetsComments\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/wsbcommentsfull\n",
      "couldnt download wallstreetbetsCommentsFull\n",
      "downloaded wikipedia\n",
      "https://api.quiverquant.com/beta/historical/congresstrading/MSFT\n",
      "downloaded congress_trading\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/cryptocomments?ticker=MSFT\n",
      "couldnt download cryptoComments\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/cryptocommentsfull?ticker=MSFT\n",
      "couldnt download cryptoCommentsHistorical\n",
      "No results found\n",
      "downloaded flights\n",
      "downloaded gov_contracts\n",
      "NOT CALLABLE  headers\n",
      "downloaded house_trading\n",
      "Drawing from:  https://api.quiverquant.com/beta/live/insiders?ticker=MSFT\n",
      "downloaded insiders\n",
      "downloaded lobbying\n",
      "downloaded offexchange\n",
      "Pulling data from:  https://api.quiverquant.com/beta/historical/allpatents/MSFT\n",
      "downloaded patents\n",
      "downloaded political_beta\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/sec13f?ticker=MSFT\n",
      "downloaded sec13F\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/sec13fchanges?ticker=MSFT\n",
      "downloaded sec13FChanges\n",
      "downloaded senate_trading\n",
      "downloaded spacs\n",
      "NOT CALLABLE  token\n",
      "downloaded twitter\n",
      "https://api.quiverquant.com/beta/historical/wallstreetbets/MSFT\n",
      "downloaded wallstreetbets\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/wsbcomments?ticker=MSFT\n",
      "couldnt download wallstreetbetsComments\n",
      "Pulling data from:  https://api.quiverquant.com/beta/live/wsbcommentsfull?ticker=MSFT\n",
      "couldnt download wallstreetbetsCommentsFull\n",
      "downloaded wikipedia\n"
     ]
    }
   ],
   "source": [
    "from Downloader import Downloader\n",
    "\n",
    "QUIVER_TOKEN = \"caccb67ee0d87402ef509d776e240dcd9a728221\"\n",
    "ALPHA_TOKEN = \"IVC83T6ZSTC846F9\"\n",
    "\n",
    "Load = Downloader(quiver_token=QUIVER_TOKEN, alpha_token=ALPHA_TOKEN)\n",
    "Load.quiver_recent() # loads today's 'live' data \n",
    "Load.quiver('msft') # loads all of the historical data for 'msft'\n",
    "Load.alpha('msft') # loads intraday 30-min freq history for 'msft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94065019-6839-4669-8765-fb8e848f3888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ditched congress_trading\n",
      "ditched political_beta\n",
      "ditched patents\n",
      "ditched flights\n",
      "Index(['sec13FChanges_Change', 'wallstreetbets_Mentions',\n",
      "       'wallstreetbets_Rank', 'wallstreetbets_Sentiment',\n",
      "       'senate_trading_Senator', 'senate_trading_Transaction',\n",
      "       'senate_trading_Amount', 'house_trading_Representative',\n",
      "       'house_trading_Transaction', 'house_trading_Amount', 'lobbying_Amount',\n",
      "       'twitter_Followers', 'twitter_pct_change_day',\n",
      "       'twitter_pct_change_week', 'twitter_pct_change_month',\n",
      "       'offexchange_OTC_Short', 'offexchange_OTC_Total', 'offexchange_DPI',\n",
      "       'wikipedia_Views', 'wikipedia_pct_change_week',\n",
      "       'wikipedia_pct_change_month', 'gov_contracts_Amount', 'spacs_Mentions',\n",
      "       'spacs_Rank', 'spacs_Sentiment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import EDA\n",
    "\n",
    "def quiver_recent_metadata():\n",
    "\n",
    "    # gathering quiver_recent file paths from data directory\n",
    "    quiver_recent_files = glob.glob(os.path.join(path, \"data/quiver_recent/*.csv\"))\n",
    "\n",
    "    # loading most of them into a dictionary with readable key names, e.g. \"congress_trading\" \n",
    "    recent_datasets = {f[63:-4] : pd.read_csv(f, index_col=0) \n",
    "        for f in quiver_recent_files }\n",
    "        #if f[63:-4] not in ['congress_trading', 'flights', 'political_beta']}\n",
    "\n",
    "    # gathering metadata for each dataset\n",
    "    metadata  = {\n",
    "        key : { \n",
    "                'name' : key,\n",
    "                \"shape\" : recent_datasets[key].shape,\n",
    "                \"columns\" : recent_datasets[key].columns,\n",
    "                \"n_columns\" : len(recent_datasets[key].columns),\n",
    "                \"n_rows\" : len(recent_datasets[key]),\n",
    "                \"tickers\" : recent_datasets[key][\"Ticker\"].unique(),\n",
    "                \"ticker_counts\" : recent_datasets[key][\"Ticker\"].value_counts().head()\n",
    "            }\n",
    "        for key in recent_datasets }\n",
    "\n",
    "    df = pd.DataFrame(metadata).transpose()\n",
    "\n",
    "    # excluding WSB becuase it's historical\n",
    "    all_but_wsb = df[df['name'] != 'wallstreetbets']\n",
    "\n",
    "    print('n rows no wsb', all_but_wsb['n_rows'].sum())\n",
    "    print('m cols no wsb', all_but_wsb['n_columns'].sum())    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af97923-df82-40b7-97c1-64c23e9d9552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
